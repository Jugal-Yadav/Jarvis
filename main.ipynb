{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pynput.mouse import Button ,Controller\n",
    "import wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3 as p\n",
    "from ipynb.fs.full.info_wiki import info\n",
    "from ipynb.fs.full.movie_reviews import *\n",
    "from ipynb.fs.full.music import *\n",
    "from ipynb.fs.full.recomendations import *\n",
    "from ipynb.fs.full.translations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse=Controller()\n",
    "\n",
    "app=wx.App(False) #initialize obj of wx\n",
    "(sx,sy)=wx.GetDisplaySize() #size of monitor\n",
    "\n",
    "(camx,camy)=(320,240) #camera will capture img in this resolution\n",
    "cap=cv2.VideoCapture(0) #attaching our in-built camera 0\n",
    "cap.set(3,camx) #setting width of the frame\n",
    "cap.set(4,camy) #setting height of the frame\n",
    "\n",
    "#range for HSV-color/saturation(1 grey)/value(brightness) (green color)\n",
    "lower_g=np.array([160,0,0])\n",
    "upper_g=np.array([180,255,255])\n",
    "\n",
    "#Kernel - filters for convolution\n",
    "kernelOpen=np.ones((5,5))\n",
    "kernelClose=np.ones((20,20))\n",
    "\n",
    "mLocOld=np.array([0,0]) #old mouse location\n",
    "mouseLoc=np.array([0,0]) #new mouse location after applying damping\n",
    "\n",
    "DampingFactor=5 #Damping factor must be greater than 1\n",
    "\n",
    "isPressed=0\n",
    "openx,openy,openw,openh=(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #initial conversation\n",
    "#     rl = sr.Recognizer()\n",
    "#     engine = p.init()\n",
    "#     engine.say(\"hello sir, how are you doing today?\")\n",
    "#     engine.runAndWait()\n",
    "#     with sr.Microphone() as source:\n",
    "#         rl.adjust_for_ambient_noise(source)\n",
    "#         print(\"check1\")\n",
    "#         audio = rl.listen(source)\n",
    "#         try:\n",
    "#             text = rl.recognize_google(audio)\n",
    "#             print(text)\n",
    "#         except sr.UnknownValueError:\n",
    "#             print(\"\")\n",
    "#         except sr.RequestError as e:\n",
    "#             print(\"\")\n",
    "    \n",
    "#     #cue for giving instructions\n",
    "#     engine.say(\"what would you like me to do?\")\n",
    "#     engine.runAndWait()\n",
    "#     print(\"check2\")\n",
    "    \n",
    "#     #giving instructions\n",
    "#     r2 = sr.Recognizer()\n",
    "#     with sr.Microphone() as source:\n",
    "#         r2.adjust_for_ambient_noise(source)\n",
    "#         audio = r2.listen(source)\n",
    "#         try:\n",
    "#             instruction = r2.recognize_google(audio)\n",
    "#             print(text)\n",
    "#         except sr.UnknownValueError:\n",
    "#             print(\"\")\n",
    "#         except sr.RequestError as e:\n",
    "#             print(\"\")\n",
    "            \n",
    "#     #getting info from wiki\n",
    "#     r3 = sr.Recognizer()\n",
    "#     if \"information\" in instruction:\n",
    "#         engine.say(\"information about what?\")\n",
    "#         engine.runAndWait()\n",
    "#         with sr.Microphone() as source1:\n",
    "#             audio2 = r3.listen(source1)\n",
    "#             try:\n",
    "#                 information = r3.recognize_google(audio2)\n",
    "#                 bot = info()\n",
    "#                 bot.get_info(information)\n",
    "#             except sr.UnknownValueError:\n",
    "#                 print(\"\")\n",
    "#             except sr.RequestError as e:\n",
    "#                 print(\"\")       \n",
    "    \n",
    "#     #movie rating\n",
    "#     r4 = sr.Recognizer()\n",
    "#     if \"review\" in instruction:\n",
    "#         engine.say(\"what is the name of the movie?\")\n",
    "#         engine.runAndWait()\n",
    "#         with sr.Microphone() as source2:\n",
    "#             audio3 = r4.listen(source2)\n",
    "#             try:\n",
    "#                 rating = r4.recognize_google(audio3)\n",
    "#                 bot = Movie()\n",
    "#                 bot.movie_review(rating)\n",
    "#             except sr.UnknownValueError:\n",
    "#                 print(\"\")\n",
    "#             except sr.RequestError as e:\n",
    "#                 print(\"\")\n",
    "                \n",
    "#     #playing music\n",
    "#     r5 = sr.Recognizer()\n",
    "#     if \"music\" in instruction:\n",
    "#         engine.say(\"which artist you want me to play?\")\n",
    "#         engine.runAndWait()\n",
    "#         with sr.Microphone() as source3:\n",
    "#             audio4 = r5.listen(source3)\n",
    "#             try:\n",
    "#                 video = r5.recognize_google(audio4)\n",
    "#                 bot = music()\n",
    "#                 bot.play(video)\n",
    "#             except sr.UnknownValueError:\n",
    "#                 print(\"\")\n",
    "#             except sr.RequestError as e:\n",
    "#                 print(\"\")   \n",
    "                \n",
    "#     #movie recomendation\n",
    "#     if \"recommendation\" in instruction:\n",
    "#         engine.say(\"here are the list of movies you can choose to watch from?\")\n",
    "#         engine.runAndWait()\n",
    "#         bot = recom()\n",
    "#         bot.recom_info() \n",
    "        \n",
    "#    #transalation\n",
    "#     r6 = sr.Recognizer()\n",
    "#     if \"meaning\" in instruction:\n",
    "#         engine.say(\"Which word sir?\")\n",
    "#         engine.runAndWait()\n",
    "#         with sr.Microphone() as source4:\n",
    "#             audio5 = r6.listen(source4)\n",
    "#             try:\n",
    "#                 word1 = r6.recognize_google(audio5)\n",
    "#                 translate(word1)\n",
    "#             except sr.UnknownValueError:\n",
    "#                 print(\"\")\n",
    "#             except sr.RequestError as e:\n",
    "#                 print(\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "\n",
    "    ret,img=cap.read() #capturing live images\n",
    "\n",
    "    imgHSV=cv2.cvtColor(img,cv2.COLOR_BGR2HSV) #converting to another color space\n",
    "    mask=cv2.inRange(imgHSV,lower_g,upper_g) #converting it to a range of green color\n",
    "\n",
    "    #using morphology to erase noise as maximum as possible \n",
    "    new_mask=cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernelOpen)\n",
    "    another_mask=cv2.morphologyEx(new_mask,cv2.MORPH_CLOSE,kernelClose)\n",
    "    final_mask=another_mask\n",
    "    \n",
    "    conts,h=cv2.findContours(final_mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)#boundary lines for constant green color objects\n",
    "\n",
    "    # Once 2 objects are detected the center of there distance will be the reference on controlling the mouse\n",
    "    if(len(conts)==2):\n",
    "\n",
    "        #if the button is pressed we need to release it first (continous clicking issue)\n",
    "        if(isPressed==1):\n",
    "            isPressed=0\n",
    "            mouse.release(Button.left)\n",
    "\n",
    "        #drawing the rectagle around both objects\n",
    "        x1,y1,w1,h1=cv2.boundingRect(conts[0])\n",
    "        x2,y2,w2,h2=cv2.boundingRect(conts[1])\n",
    "        cv2.rectangle(img,(x1,y1),(x1+w1,y1+h1),(255,0,0),2)\n",
    "        cv2.rectangle(img,(x2,y2),(x2+w2,y2+h2),(255,0,0),2)\n",
    "\n",
    "        #the line between the center of the previous rectangles\n",
    "        cx1=int(x1+w1/2)\n",
    "        cy1=int(y1+h1/2)\n",
    "        cx2=int(x2+w2/2)\n",
    "        cy2=int(y2+h2/2)\n",
    "        cv2.line(img,(cx1,cy1),(cx2,cy2),(255,0,0),2)\n",
    "\n",
    "        #the center of that line (reference point)\n",
    "        clx=int((cx1+cx2)/2)\n",
    "        cly=int((cy1+cy2)/2)\n",
    "        cv2.circle(img,(clx,cly),2,(0,0,255),2)\n",
    "\n",
    "        #adding the damping factor so that the movement of the mouse is smoother\n",
    "        mouseLoc=mLocOld+((clx,cly)-mLocOld)/DampingFactor\n",
    "        mouse.position=(sx-int((mouseLoc[0]*sx)/camx),int((mouseLoc[1]*sy)/camy))#passing damped mouse location\n",
    "        while mouse.position!=(sx-int((mouseLoc[0]*sx)/camx),int((mouseLoc[1]*sy)/camy)):\n",
    "            pass #wait till captured image resolution is not converted to our window(screen) size resolution\n",
    "\n",
    "        #setting the old location to the current mouse location\n",
    "        mLocOld=mouseLoc\n",
    "\n",
    "        #these variables were added so that we get the outer rectangle that combines both objects \n",
    "        openx,openy,openw,openh=cv2.boundingRect(np.array([[[x1,y1],[x1+w1,y1+h1],[x2,y2],[x2+w2,y2+h2]]]))\n",
    "\n",
    "    #when there's only one object detected it will act as a left click mouse and will keep on clicking which we don't want   \n",
    "    elif(len(conts)==1):\n",
    "        x,y,w,h=cv2.boundingRect(conts[0])\n",
    "\n",
    "        # we check first and we allow the press fct if it's not pressed yet\n",
    "        #we did that to avoid the continues pressing \n",
    "        if(isPressed==0):\n",
    "\n",
    "            if(abs((w*h-openw*openh)*100/(w*h))<30): #the difference between the combined rectangle for both objct and the \n",
    "                isPressed=1                          #the outer rectangle is not more than 30%\n",
    "                mouse.press(Button.left)\n",
    "                openx,openy,openw,openh=(0,0,0,0)\n",
    "\n",
    "        #this else was added so that if there's only one object detected it will not act as a mouse  \n",
    "        else:\n",
    "            #getting rectangle coordinates and drawing it \n",
    "            x,y,w,h=cv2.boundingRect(conts[0])\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "            #getting the center of the circle that will be inside the outer rectangle\n",
    "            cx=int(x+w/2)\n",
    "            cy=int(y+h/2)\n",
    "            cv2.circle(img,(cx,cy),int((w+h)/4),(0,0,255),2)#drawing that circle\n",
    "\n",
    "            mouseLoc=mLocOld+((cx,cy)-mLocOld)/DampingFactor\n",
    "            mouse.position=(sx-int((mouseLoc[0]*sx)/camx),int((mouseLoc[1]*sy)/camy))#passing damped mouse location\n",
    "            while mouse.position!=(sx-int((mouseLoc[0]*sx)/camx),int((mouseLoc[1]*sy)/camy)):\n",
    "                pass #wait till captured image resolution is not converted to our window size resolution\n",
    "            mLocOld=mouseLoc\n",
    "\n",
    "        \n",
    "\n",
    "    #showing the results \n",
    "    cv2.imshow(\"Virtual mouse\",img)\n",
    "    \n",
    "    #waiting for 'W' to be pressed to quit \n",
    "    if cv2.waitKey(1) & 0xFF==ord('w'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
